{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuantifiedMe\n",
    "============\n",
    "\n",
    " - **Created by:** Erik Bjäreholt   ([GitHub](https://github.com/ErikBjare), [Twitter](https://twitter.com/ErikBjare), [LinkedIn](https://www.linkedin.com/in/erikbjareholt/))\n",
    " - **Latest version:** https://erik.bjareholt.com/quantifiedme/Dashboard.html\n",
    " - **Source:** https://github.com/ErikBjare/quantifiedme\n",
    "\n",
    "QuantifiedMe is a collection of software tools for quantified self data. It is used to measure and manage behavior, productivity, health, habits, and life in general.\n",
    "\n",
    "This public notebook is limited to time tracking data, with actual example data generated by [aw-fakedata](https://github.com/ActivityWatch/aw-fakedata)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "- [Introduction](#Introduction)\n",
    "- [Setup](#Setup)\n",
    "  - [Configuration](#Configuration)\n",
    "- [Load data](#Load-data)\n",
    "  - [Verify data](#Verify-data)\n",
    "- [Visualize](#Visualize)\n",
    "  - [Today plot](#Today-plot)\n",
    "  - [Trends plot](#Trends-plot)\n",
    "  - [Category sunburst](#Category-sunburst)\n",
    "  - [Fictional wage plot](#Fictional-wage-plot)\n",
    "  - [Uncategorized](#Uncategorized)\n",
    "- [Closing remarks](#Closing-remarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The phrase *\"What gets measured gets managed\"* is sometimes thrown around in professional contexts. While often just appreciated for its contextual face value, it's actually an important observation that today drives practically the entire world. Companies measure performance and financial results, engineering teams measure keep track of their tasks and resources, and scientists measure everything from health outcomes to the trajectory of interstellar objects that could threaten the planet.\n",
    "\n",
    "Indeed, collecting and analysing data is the foundation for all of science, or as Lord Kelvin put it:\n",
    "\n",
    "> *I often say that when you can measure what you are speaking about, and express it in numbers, you know something about it; but when you cannot express it in numbers, your knowledge is of a meagre and unsatisfactory kind; it may be the beginning of knowledge, but you have scarcely, in your thoughts, advanced to the stage of science, whatever the matter may be.*\n",
    ">\n",
    ">   ***–  William Thomson*** (Lord Kelvin), Lecture on \"Electrical Units of Measurement\" (1883)\n",
    "\n",
    "**However**, although commonly practiced in professional contexts and having words thrown around like \"data-driven\", it's less common in our personal lives. We generally don't see problems in our personal lives as matters that could be solved through measuring and analysing. This is probably because we don't know which questions to ask, or that it seems too difficult to collect and analyze the data because we're unaware of the tools to get the job done, or simply because we compartmentalize the scientific method as a \"work thing\", or as something to be left to \"real scientists\". \n",
    "\n",
    "So what if we had good open-source tools to easily ask questions and explore data about our personal lives? What if people shared the data with each other, and together worked on common personal problems (productivity, mental & physical health, work/life balance) in a truly scientific way? I think that seems worthy of exploring.\n",
    "\n",
    "I've built some of those tools over the past years, among them the open-source time tracker [ActivityWatch](https://activitywatch.net/), and here's a little showcase of some of my work over that time. I've used a notebook like this one almost every week for almost a year to explore my behavior (many of the things didn't make the cut, sorry). It's been both fascinating and rich in insights about how I spend my time, and how I could do better in big and small ways. But the inquiry has just started, there's a lot more to come.\n",
    "\n",
    "Now, dear reader, I've blabbered enough. Enjoy my work, I hope you find it of interest (and use!). Be sure to check out some of the links at the end for more stuff like this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "First we do some imports, and set some variables used in the rest of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import logging\n",
    "import itertools\n",
    "from datetime import datetime, time, date, timezone, timedelta\n",
    "from pathlib import Path\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "from IPython.utils import io\n",
    "from IPython.display import display\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import aw_core\n",
    "from aw_core.models import Event\n",
    "\n",
    "import aw_research, aw_research.classify\n",
    "from aw_transform import union_no_overlap\n",
    "\n",
    "from quantifiedme.config import load_config\n",
    "from quantifiedme.derived.screentime import load_screentime\n",
    "\n",
    "# Use XKCD-style plots\n",
    "# FIXME: Causes the day trend plots to take forever for some unknown reason\n",
    "# matplotlib.pyplot.xkcd(scale=0.8, randomness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Modify these to your liking!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set this to your timezone\n",
    "your_timezone = pytz.timezone('Europe/Stockholm')\n",
    "tz_offset = your_timezone.utcoffset(datetime.now())\n",
    "\n",
    "# Use personal data, not fake data\n",
    "personal = True\n",
    "\n",
    "# Set to True to limit amount of data loaded (useful when developing/debugging)\n",
    "fast = False\n",
    "\n",
    "# Can be set to True to run faster on consequtive runs, but will not reflect changes in data,\n",
    "# so needs to be set to False every now and then to clear the cache.\n",
    "cache = True\n",
    "    \n",
    "# Days of history to use\n",
    "days_back = 30 if fast else 5*365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below sets the window title to something more descriptive so that ActivityWatch can track that I'm working on this specific notebook (since the default isn't informative in JupyterLab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "document.title='QuantifiedMe - Jupyter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now let's just set the current time and our query interval and we're ready to load data!\n",
    "# If not running in personal mode, use a fixed datetime to make notebook reproducible\n",
    "now = datetime.now(tz=timezone.utc) if personal else datetime(2021, 6, 9, tzinfo=timezone.utc)\n",
    "day_offset = timedelta(hours=4)\n",
    "today = datetime.combine(now.date(), time()).astimezone(timezone.utc) + day_offset\n",
    "since = today - timedelta(days=days_back)\n",
    "\n",
    "print(f\"Today:  {today.date()}\")\n",
    "print(f\"Start:  {since}\")\n",
    "print(f\"End:    {now}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "We will load data from all sources into the `events` variable. \n",
    "\n",
    "Every consecutive source source will fill eventual gaps from previous sources (to prevent overlap), by using `union_no_overlap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using my syncing testing instance to get multi-device data\n",
    "events = load_screentime(since, datasources=None, hostnames=None, personal=personal, cache=cache)\n",
    "print(f\"First: {events[0].timestamp}\")\n",
    "print(f\"Last:  {events[-1].timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the events to a file so we can load them faster next time\n",
    "import pickle\n",
    "with open('events.pickle', 'wb') as f:\n",
    "    pickle.dump(events, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data\n",
    "\n",
    "Now lets take a look at the data. Could help us discover potential bugs in loading code or issues with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inspect the distribution of event duration\n",
    "fig, ax = plt.subplots()\n",
    "xlim = 50\n",
    "pd.Series([e.duration.total_seconds() for e in events if e.duration.total_seconds() <= xlim]).plot.hist(bins=10, bottom=1)\n",
    "ax.set_xlabel('Seconds')\n",
    "ax.set_ylabel('# of events')\n",
    "ax.set_xlim(0, xlim)\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "#df = pd.DataFrame(pd.Series([e.duration.total_seconds() for e in events]))\n",
    "#df[\"dur\"] = (df[0] // 10) * 10\n",
    "#df[\"logdur\"] = log((df[0] * 1).round())\n",
    "#df[df[\"dur\"] > 10][\"dur\"].plot.hist()\n",
    "#df.groupby(\"dur\").mean() * df.groupby(\"dur\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the longest event\n",
    "longest = sorted(events, key=lambda e: e.duration, reverse=True)[0]\n",
    "print(f\"Longest duration event was {longest.duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xlim = 5\n",
    "pd.Series([e.duration.total_seconds() for e in events if e.duration.total_seconds() <= xlim]).plot.hist(bins=10, bottom=1)\n",
    "ax.set_xlabel('Seconds')\n",
    "ax.set_ylabel('# of events')\n",
    "ax.set_xlim(0, xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlim = 2\n",
    "pd.Series([e.duration.total_seconds() for e in events if e.duration.total_seconds() <= xlim]).plot.hist(bins=10, bottom=1)\n",
    "ax.set_xlabel('Seconds')\n",
    "ax.set_ylabel('# of events')\n",
    "ax.set_xlim(0, xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "total_events = len(events)\n",
    "short_thres = 5\n",
    "short_events = len([e for e in events if e.duration.total_seconds() < short_thres])\n",
    "print(f\"# of total events:  {total_events}\")\n",
    "print(f\"# of events <{short_thres}s:    {short_events} ({round(100 * short_events/total_events)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How much time is covered?\n",
    "\n",
    "How much of the time in the range has been tracked?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Include sleep for improved coverage\n",
    "tracking_cov = __builtins__.sum((e.duration for e in events), timedelta()) / (now - since)\n",
    "print(f\"Tracking coverage: {100 * tracking_cov:.3}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which devices are used the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_by_source = defaultdict(float)\n",
    "df_rows = []\n",
    "for e in events:\n",
    "    date = e.timestamp.date()\n",
    "    source = e.data.get('$source', 'unknown')\n",
    "    host = e.data.get('$hostname', 'unknown')\n",
    "    duration = e.duration.total_seconds()\n",
    "    time_by_source[host] += duration\n",
    "    df_rows.append([date, source, host, duration])\n",
    "    \n",
    "def line_format(label):\n",
    "    \"\"\"\n",
    "    Convert time label to the format of pandas line plot\n",
    "    From: https://stackoverflow.com/a/53995225/965332\n",
    "    \"\"\"\n",
    "    month = label.month_name()[:3]\n",
    "    if month == 'Jan':\n",
    "        month += f'\\n{label.year}'\n",
    "    return month\n",
    "    \n",
    "    \n",
    "df = pd.DataFrame(df_rows, columns=[\"date\", \"source\", \"host\", \"duration\"])\n",
    "df = df.set_index([\"date\", \"source\", \"host\"])\n",
    "df = df.groupby(level=[0,1,2]).sum()\n",
    "df /= 60*60\n",
    "df = df.unstack(level=2).fillna(0).reset_index().set_index('date')\n",
    "\n",
    "df = df.drop(columns='source')\n",
    "df = df.groupby(level=0).sum()\n",
    "\n",
    "timeline = pd.to_datetime(pd.date_range(start=df.index[0], end=df.index[-1], freq='D'))\n",
    "timeline_months = [date for date in timeline if date.day == 1]\n",
    "\n",
    "# Add missing dates\n",
    "df = df.reindex(pd.to_datetime(timeline), fill_value=0)\n",
    "\n",
    "# Drop 'duration' level into individual hostname columns\n",
    "df.columns = df.columns.droplevel(0)\n",
    "assert len(df[df.index.duplicated()]) == 0\n",
    "\n",
    "import matplotlib.dates as mdates\n",
    "ax = df.plot.bar(stacked=True, figsize=(30, 4), ylim=(0, None), rot=0)\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "ax.set_xticklabels(map(line_format, timeline_months));\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"source\": time_by_source.keys(), \"duration\": time_by_source.values()})\n",
    "df['days'] = df['duration'] / (60*60*24)\n",
    "df.plot.bar(x='source', y='days', rot=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize\n",
    "\n",
    "We know have events loaded from a variety of sources, annotated with categories and tags. **Here comes the fun part!**\n",
    "\n",
    "Here are some visualizations I've found useful to show how your activity today, over many days, and how much you've spent in each category.\n",
    "\n",
    "TODO: Add calendar heatmap plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today plot\n",
    "\n",
    "Barchart of which hours you've been active today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from aw_research import split_event_on_hour, categorytime_per_day, categorytime_during_day, start_of_day, end_of_day\n",
    "    \n",
    "def plot_categorytime_during_day(events, category, color='teal'):\n",
    "    df = categorytime_during_day(events, category, today)\n",
    "    \n",
    "    # FIXME: This will make the first and last hour to always be 0\n",
    "    ix = pd.date_range(start=start_of_day(today) + day_offset - tz_offset,\n",
    "                         end=start_of_day(today) + timedelta(hours=24) + day_offset - tz_offset,\n",
    "                         freq='H')\n",
    "    df = df.reindex(ix)\n",
    "    df = df.sort_index().asfreq('H')\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 3))\n",
    "    ax = df.plot(kind='bar', color=color, rot=60)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.title(category or \"All activity\")\n",
    "    \n",
    "    def label_format_hour(label):\n",
    "        \"\"\"\n",
    "        Convert time label to the format of pandas line plot\n",
    "        Based on: https://stackoverflow.com/a/53995225/965332\n",
    "        \"\"\"\n",
    "        label = label.replace(tzinfo=your_timezone)\n",
    "        label = label + label.utcoffset()\n",
    "        return f\"{label.hour}:{str(label.minute).ljust(2, '0')}\"  # if label.hour % 2 == 0 else ''\n",
    "        \n",
    "    ax.set_xticklabels([label_format_hour(dt) for dt in df.index])\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_categorytime_during_day(events, \"\")\n",
    "plot_categorytime_during_day(events, \"Work\", color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantifiedme.timelineplot.plot import TimelineFigure\n",
    "import matplotlib\n",
    "\n",
    "fig = TimelineFigure(title=\"Timeline\")\n",
    "\n",
    "# TODO: plot timeline with bars colored according to: \n",
    "#       - [ ] device used\n",
    "#       - [x] category \n",
    "#            - [ ] would be better with category colors configured\n",
    "\n",
    "def dayevents_to_barsegments(events, colorkey='$hostname', cmap=matplotlib.colormaps['tab10']):\n",
    "    # useful colorkey values: app, $hostname, $category_hierarchy\n",
    "    groups = {}\n",
    "    for e in events:\n",
    "        if e.duration.total_seconds() < 5:\n",
    "           continue\n",
    "        t1 = e.timestamp.time()\n",
    "        t2 = (e.timestamp + e.duration).time()\n",
    "        if t1 > t2:\n",
    "            # event crossing midnight, skip\n",
    "            continue\n",
    "        start = t1.hour * 60 * 60 + t1.minute * 60 + t1.second\n",
    "        stop  = t2.hour * 60 * 60 + t2.minute * 60 + t2.second\n",
    "        key   = e.data[colorkey]\n",
    "        if key not in groups:\n",
    "            groups[key] = len(groups)\n",
    "        color = cmap(groups[key]) \n",
    "        yield ((start, stop), color, '')\n",
    "    \n",
    "\n",
    "# split events into days, days into bar segments\n",
    "for date, dayevents in itertools.groupby(sorted(events, key=lambda e: e.timestamp), lambda e: e.timestamp.date()):\n",
    "    dayevents = list(dayevents)\n",
    "    second_of_day = e.timestamp.time()\n",
    "    bar = [segment for segment in dayevents_to_barsegments(dayevents)]\n",
    "    if bar:\n",
    "        fig.add_bar(bar, title=str(date))\n",
    "    \n",
    "ticks = list(range(0, 24 * 60 * 60, 60 * 60))\n",
    "labels = [str(t // (60*60)) for t in ticks] \n",
    "fig.ax.set_xticks(ticks, labels)\n",
    "fig.ax.grid(True, axis=\"x\", linestyle='--', linewidth=1, zorder=-1000, alpha=0.4)\n",
    "fig.plot()\n",
    "# Needs extra work with matplotlib \"artists\" (never used before)\n",
    "#fig.ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trends plot\n",
    "\n",
    "Useful to see how much you've engaged in a particular activity over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_category(cat, big=False, barcolor=(0.2, 0.4, 0.8, 0.5)):\n",
    "    #aw_research.classify._plot_category_daily_trend(events, [cat])\n",
    "    try:\n",
    "        ts  = categorytime_per_day(events, cat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for category '{cat}': {e}\")\n",
    "        return\n",
    "    fig, ax = plt.subplots(figsize=(24, 5 if big else 3))\n",
    "    ax.bar(ts.index, ts, label=f\"{cat}: daily\", color=barcolor)\n",
    "    ax.plot(ts.index, ts.rolling(7, min_periods=4).mean(), label=f\"7d SMA\")\n",
    "    ax.plot(ts.index, ts.rolling(30, min_periods=14).mean(), label=f\"30d SMA\")\n",
    "    ax.plot(ts.index, ts.rolling(60, min_periods=30).mean(), label=f\"60d SMA\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(cat)\n",
    "    plt.xlim(pd.Timestamp(since), pd.Timestamp(now))\n",
    "    plt.ylim(0)\n",
    "    plt.grid(linestyle='--')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "color_prod = (0.1, 0.8, 0.1, 0.8)\n",
    "color_unprod = (0.8, 0.1, 0.1, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# All logged activity\n",
    "plot_category('', big=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Work-related\n",
    "plot_category('Work', big=True, barcolor=color_prod)\n",
    "plot_category('Programming')\n",
    "plot_category('ActivityWatch')\n",
    "plot_category('QuantifiedMe')\n",
    "plot_category('Thankful')\n",
    "plot_category('Algobit')\n",
    "plot_category('uniswap-python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# School-related\n",
    "plot_category('School')\n",
    "plot_category('Self-directed')\n",
    "plot_category('Maths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Entertainment\n",
    "plot_category('Media', big=True, barcolor=color_unprod)\n",
    "plot_category('Social Media')\n",
    "plot_category('Video')\n",
    "plot_category('Music')\n",
    "plot_category('Games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# All uncategorized time\n",
    "plot_category('Uncategorized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category sunburst\n",
    "\n",
    "Uses the category hierarchy to create an overview of how time has been spent during a given period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "events_today = [e for e in events if today < e.timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_sunburst(events):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    aw_research.classify._plot_category_hierarchy_sunburst(events)\n",
    "    display(HTML(f\"<b>Total duration: {__builtin__.sum((e.duration for e in events), timedelta(0))}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_sunburst(events_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_sunburst([e for e in events if today - timedelta(days=30) < e.timestamp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plot_sunburst(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fictional wage plot\n",
    "\n",
    "Prioritizing things in life can be hard, and it's not uncommon to want to maximize how much you earn. But how much is working on project X actually worth to you in monetary terms? What about project Y?\n",
    "\n",
    "By assigning hourly wages to different categories we can plot which activities we've earned the most (fictional) money from! This can help you identify how much you expect to have earned both from different activities and in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# NOTE: Setting a rate for a subcategory will add to the rate for the parent category, if any\n",
    "category_wages = {\n",
    "    \"Work\": 30,  # Base rate\n",
    "    \"ActivityWatch\": 15,  # In addition to the base rate\n",
    "    \"QuantifiedMe\": 40,   # Self-analyzing my behavior probably has high returns\n",
    "    \"Thankful\": 40,\n",
    "    \"School\": 60,\n",
    "    \"Algobit\": 100,\n",
    "    \"Finance\": 100,\n",
    "}\n",
    "\n",
    "def plot_wages(events, category_wages):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    for cat, wage in category_wages.items():\n",
    "        try:\n",
    "            df[cat] = wage * categorytime_per_day(events, cat)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception for category {cat}: {e}\")\n",
    "    df.plot.area(label='total', stacked=True, figsize=(16, 4), ax=ax1, legend=False)\n",
    "    ax1.set_ylabel(\"Daily wage ($)\")\n",
    "    ax1.legend(loc=1)\n",
    "    \n",
    "    #ax2 = ax1.twinx()\n",
    "    #df.sum(axis=1).rolling(7).mean().plot(label='Total 7d SMA', legend=False, ax=ax2)\n",
    "    df.sum(axis=1).rolling(30).mean().plot(label='Total 30d SMA', legend=False, ax=ax1)\n",
    "    #ax2.set_ylabel(\"Daily wage ($)\")\n",
    "    #ax2.legend(loc=2)\n",
    "    plt.xlim(pd.Timestamp(since), pd.Timestamp(now))\n",
    "    plt.grid(linestyle='-.')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_wages(events, category_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Category checks\n",
    "\n",
    "Lets dig into some categories to see what they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncategorized\n",
    "\n",
    "To check for events we could classify better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def time_per_keyval(events, key):\n",
    "    vals = defaultdict(lambda: timedelta(0))\n",
    "    for e in events:\n",
    "        if key in e.data:\n",
    "            vals[e.data[key]] += e.duration\n",
    "        else:\n",
    "            vals[f'key {key} did not exist'] += e.duration\n",
    "    return vals\n",
    "\n",
    "def print_time_per_keyval(events, key, limit=20, sortby='duration'):\n",
    "    from tabulate import tabulate\n",
    "    if sortby == 'duration':\n",
    "        l = sorted([(v, k) for k, v in time_per_keyval(events, key).items()], reverse=True)\n",
    "    elif sortby == 'key':\n",
    "        l = sorted([(k, v) for k, v in time_per_keyval(events, key).items()], reverse=True)\n",
    "    else:\n",
    "        raise ValueError(f'invalid option for sortby, was \"{sortby}\"')\n",
    "    print(tabulate(l[:limit], headers=['time', 'val']))\n",
    "    \n",
    "events_uncategorized = [e for e in events if 'Uncategorized' in e.data['$tags']]\n",
    "print_time_per_keyval(events_uncategorized, 'title', limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "events_uncategorized_today = [e for e in events_uncategorized if e.timestamp > today]\n",
    "print_time_per_keyval(events_uncategorized_today, 'title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underspecified categories\n",
    "\n",
    "Lets dig into a category with many children to see if some events can be classified better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "events_programming = [e for e in events if 'Work -> Programming' == e.data['$category_hierarchy']]\n",
    "print_time_per_keyval(events_programming, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#print_time_per_keyval(events, \"$category_hierarchy\", limit=100, sortby='key')\n",
    "#tabulate(set(e.data[\"$category_hierarchy\"] for e in events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print_time_per_keyval(events, '$source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category tree\n",
    "\n",
    "Build a tree structure to compute aggregate times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from aw_research.tree import Node\n",
    "\n",
    "def build_tree(data: dict):\n",
    "    root = Node('root', timedelta())\n",
    "    for k, v in sorted(data.items()):\n",
    "        hier = k.split(\" -> \")\n",
    "        parent = root\n",
    "        # Get (or create) parent\n",
    "        for level in hier[:-1]:\n",
    "            if not level in parent:\n",
    "                # Create parent node\n",
    "                parent += Node(level, timedelta())\n",
    "            parent = parent[level]\n",
    "        # Create child node\n",
    "        level = hier[-1]\n",
    "        if level not in parent:\n",
    "            parent += Node(level, v)\n",
    "        else:\n",
    "            print(\"Unexpected!\")\n",
    "    return root\n",
    "        \n",
    "root = build_tree(time_per_keyval(events, '$category_hierarchy'))\n",
    "print(root.print())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closing remarks\n",
    "\n",
    "That's the end of the notebook, thank you for checking it out! \n",
    "\n",
    "I hope you'll upvote and/or comment wherever you saw it to help it get seen!\n",
    "\n",
    "### Share & donate!\n",
    "\n",
    "**Did you like it? Consider supporting us so we can keep building!**\n",
    "\n",
    " - TODO: Add link/image/button to Patreon\n",
    " - Like ActivityWatch on AlternativeTo! (TODO: ...and ProductHunt)\n",
    " - Post about it on Twitter!\n",
    "\n",
    "### Run it yourself!\n",
    "\n",
    "You can run this notebook with your own data, it's a lot more fun! \n",
    "\n",
    "Download and install [ActivityWatch](https://activitywatch.net), then check out the [quantifiedme repo]( https://github.com/ErikBjare/quantifiedme) for usage instructions.\n",
    "\n",
    " - TODO: Actually add details for how to run it in the README\n",
    " \n",
    "### Other interesting links\n",
    "\n",
    " - [Memento Labs](https://mementolabs.io/), a platform for self-study using quantified self data.\n",
    "\n",
    "### Thanks to\n",
    "\n",
    " - [Johan Bjäreholt](https://github.com/johan-bjareholt), my brother, for his amazing contributions, and for working on ActivityWatch with me for so long. **This wouldn't be possible without him.**\n",
    " - All the other contributors, whose [stats are listed here](http://activitywatch.net/contributors/).\n",
    " - Our Patrons/backers/supporters, your financial contribution means a lot!\n",
    " - [@karpathy](https://twitter.com/karpathy) for creating [ulogme](https://github.com/karpathy/ulogme), a spiritual ancestor of ActivityWatch\n",
    " - Our users, you motivate us to keep working!\n",
    " \n",
    " \n",
    " ## TODO: Post to\n",
    " \n",
    "  - Reddit\n",
    "  - Hacker News\n",
    "  - Twitter\n",
    "  - ActivityWatch Forum (under the 'Projects' category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantifiedme",
   "language": "python",
   "name": "quantifiedme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
