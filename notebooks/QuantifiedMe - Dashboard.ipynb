{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "QuantifiedMe\n",
    "============\n",
    "\n",
    "**Created by:** Erik Bjäreholt   ([GitHub](https://github.com/ErikBjare), [Twitter](https://twitter.com/ErikBjare), [LinkedIn](https://www.linkedin.com/in/erikbjareholt/))\n",
    "\n",
    "**View the latest built version at: Link not yet available (TODO)**\n",
    "<br>\n",
    "**Get the code at: https://github.com/ErikBjare/quantifiedme**\n",
    "\n",
    "Tools using rich data, decent metrics, and pretty visualizations, for measuring and managing behavior, productivity, health, and life in general.\n",
    "\n",
    "\n",
    "# You are viewing a **code-only** notebook, there won't be any output or visualizations!\n",
    "\n",
    "A notebook that includes output and visualizations will be created \"soon\"!\n",
    "\n",
    "~~**Do you just want to see pretty visualizations? Scroll down to the \"Visualize\" section!**~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The phrase *\"What gets measured gets managed\"* is sometimes thrown around in professional contexts. While often just appreciated for its contextual face value, it's actually an important observation that today drives practically the entire world. Companies measure performance and financial results, engineering teams measure keep track of their tasks and resources, and scientists measure everything from health outcomes to the trajectory of interstellar objects that could threaten the planet.\n",
    "\n",
    "Indeed, collecting and analysing data is the foundation for all of science, or as Lord Kelvin put it:\n",
    "\n",
    "> *I often say that when you can measure what you are speaking about, and express it in numbers, you know something about it; but when you cannot express it in numbers, your knowledge is of a meagre and unsatisfactory kind; it may be the beginning of knowledge, but you have scarcely, in your thoughts, advanced to the stage of science, whatever the matter may be.*\n",
    ">\n",
    ">   ***–  William Thomson*** (Lord Kelvin), Lecture on \"Electrical Units of Measurement\" (1883)\n",
    "\n",
    "**However**, although commonly practiced in professional contexts and having words thrown around like \"data-driven\", it's less common in our personal lives. We generally don't see problems in our personal lives as matters that could be solved through measuring and analysing. This is probably because we don't know which questions to ask, or that it seems too difficult to collect and analyze the data because we're unaware of the tools to get the job done, or simply because we compartmentalize the scientific method as a \"work thing\", or as something to be left to \"real scientists\". \n",
    "\n",
    "So what if we had good open-source tools to easily ask questions and explore data about our personal lives? What if people shared the data with each other, and together worked on common personal problems (productivity, mental & physical health, work/life balance) in a truly scientific way? I think that seems worthy of exploring.\n",
    "\n",
    "I've built some of those tools over the past years, among them the open-source time tracker [ActivityWatch](https://activitywatch.net/), and here's a little showcase of some of my work over that time. I've used a notebook like this one almost every week for almost a year to explore my behavior (many of the things didn't make the cut, sorry). It's been both fascinating and rich in insights about how I spend my time, and how I could do better in big and small ways. But the inquiry has just started, there's a lot more to come.\n",
    "\n",
    "Now, dear reader, I've blabbered enough. Enjoy my work, I hope you find it of interest (and use!). Be sure to check out some of the links at the end for more stuff like this!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "- [Setup](#Setup)\n",
    "- [Load data](#Load-data)\n",
    "  - [Generate fake data](#Load-Toggl-data)\n",
    "  - [Load ActivityWatch data](#Load-ActivityWatch-data)\n",
    "  - [Load SmarterTime data](#Load-SmarterTime-data)\n",
    "  - [Load Toggl data](#Load-Toggl-data)\n",
    "  - [Annotate data](#Annotate-data)\n",
    "- [Visualize](#Visualize)\n",
    "  - [Daily time plot](#Daily-time-plot)\n",
    "  - [Category sunburst plot](#Category-sunburst-plot)\n",
    "  - [Fictional wage plot](#Fictional-wage-plot)\n",
    "  - [Uncategorized](#Fictional-wage-plot)\n",
    "  \n",
    "TODO: Build the table of contents automatically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "First we do some imports, and set some variables used in the rest of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time, date, timezone, timedelta\n",
    "from pathlib import Path\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pytz\n",
    "from IPython.utils import io\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import aw_core\n",
    "from aw_core.models import Event\n",
    "import aw_research, aw_research.classify\n",
    "from aw_research.classify import _union_no_overlap\n",
    "from aw_research import verify_no_overlap, split_into_weeks, split_into_days\n",
    "\n",
    "# Use XKCD-style plots\n",
    "# FIXME: Causes the day trend plots to take forever for some unknown reason\n",
    "# matplotlib.pyplot.xkcd(scale=0.8, randomness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "**Modify these to your liking!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to your timezone\n",
    "your_timezone = pytz.timezone('Europe/Stockholm')\n",
    "tz_offset = your_timezone.utcoffset(datetime.now())\n",
    "\n",
    "# Use personal data, not fake data\n",
    "personal = False\n",
    "\n",
    "# Choose where to fetch data from\n",
    "# Valid options: 'activitywatch', 'smartertime', 'toggl', 'fake'\n",
    "if personal:\n",
    "    # List of sources from which to fetch data when running in personal mode\n",
    "    datasources = ['activitywatch', 'smartertime'] #, 'toggl']\n",
    "else:\n",
    "    # Use fake data if not in personal mode\n",
    "    datasources = ['fake']\n",
    "    \n",
    "# Days of history to use\n",
    "days_back = 360"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below sets the window title to something more descriptive so that ActivityWatch can track that I'm working on this specific notebook (since the default isn't informative in JupyterLab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "document.title='QuantifiedMe - Jupyter'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set current time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's just set the current time and our query interval and we're ready to load data!\n",
    "# If not running in personal mode, use a fixed datetime to make notebook reproducible\n",
    "now = datetime.now(tz=timezone.utc) if personal else datetime(2019, 6, 1).astimezone(timezone.utc)\n",
    "day_offset = timedelta(hours=4)\n",
    "today = datetime.combine(now.date(), time()).astimezone(timezone.utc) + day_offset\n",
    "since = today - timedelta(days=days_back)\n",
    "\n",
    "print(f\"Today:  {today.date()}\")\n",
    "print(f\"Start:  {since}\")\n",
    "print(f\"End:    {now}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "\n",
    "We will load data from all sources into the `events` variable. \n",
    "\n",
    "Every consecutive source source will fill eventual gaps from previous sources (to prevent overlap), by using `_union_no_overlap`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate fake data\n",
    "\n",
    "So I can show you the plots in this notebook without sacrificing my privacy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_weights = [\n",
    "    (100, None),\n",
    "    (2, {'title': 'Uncategorized'}),\n",
    "    (5, {'title': 'ActivityWatch'}),\n",
    "    (4, {'title': 'Thankful'}),\n",
    "    (3, {'title': 'QuantifiedMe'}),\n",
    "    (3, {'title': 'FMAA01 - Analysis in One Variable'}),\n",
    "    (3, {'title': 'EDAN95 - Applied Machine Learning'}),\n",
    "    (2, {'title': 'Stack Overflow'}),\n",
    "    (2, {'title': 'phone: Brilliant'}),\n",
    "    (2, {'url': 'youtube.com', 'title': 'YouTube'}),\n",
    "    (1, {'url': 'reddit.com'}),\n",
    "    (1, {'url': 'facebook.com'}),\n",
    "    (1, {'title': 'Plex'}),\n",
    "    (1, {'title': 'Spotify'}),\n",
    "    (1, {'title': 'Fallout 4'}),\n",
    "]\n",
    "\n",
    "def create_fake_events(start: datetime, end: datetime):\n",
    "    # First set RNG seeds to make the notebook reproducible\n",
    "    random.seed(0)  \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    pareto_alpha = 0.5\n",
    "    pareto_mode = 5\n",
    "    time_passed = timedelta()\n",
    "    while start + time_passed < end:\n",
    "        duration = timedelta(seconds=np.random.pareto(pareto_alpha) * pareto_mode)\n",
    "        duration = min([timedelta(hours=1), duration])\n",
    "        timestamp = start + time_passed\n",
    "        data = random.choices([d[1] for d in data_weights], [d[0] for d in data_weights])[0]\n",
    "        if data:\n",
    "            yield Event(timestamp=timestamp, duration=duration, data=data)\n",
    "        time_passed += duration\n",
    "    \n",
    "if 'fake' in datasources:\n",
    "    fake_events = list(create_fake_events(start=since.astimezone(timezone.utc), end=now.astimezone(timezone.utc)))\n",
    "    events += fake_events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ActivityWatch data\n",
    "\n",
    "Retrieve events from aw-server. Queried for active windows combined with browser history and filters by AFK/audible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'activitywatch' in datasources:\n",
    "    # Split up into previous days and today, to take advantage of caching\n",
    "    # TODO: Split up into whole days\n",
    "    events_aw = []\n",
    "    for dtstart, dtend in split_into_weeks(since, now):\n",
    "        events_aw += aw_research.classify.get_events(since=dtstart, end=dtend, include_smartertime=False, include_toggl=False)\n",
    "        print(len(events_aw))\n",
    "    for e in events_aw:\n",
    "        e.data['$source'] = 'activitywatch'\n",
    "\n",
    "    events = _union_no_overlap(events, events_aw)\n",
    "    verify_no_overlap(events)\n",
    "    \n",
    "# The above code does caching using joblib, use the following if you want to clear the cache:\n",
    "# aw_research.classify.memory.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load SmarterTime data\n",
    "\n",
    "[SmarterTime](https://play.google.com/store/apps/details?id=com.smartertime&hl=en) is an Android app that tracks app usage. It was primarily used by me before I got ActivityWatch on Android working (but is still, for old data).\n",
    "\n",
    "The code loads an ActivityWatch bucket that I converted from the app export (so there's one step here I haven't shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_smartertime():\n",
    "    events_smartertime = []\n",
    "    for smartertime_awbucket_path in [\n",
    "        'data/smartertime/smartertime_export_erb-a1_2019-02-18_bb7f26aa.awbucket.json',\n",
    "        'data/smartertime/smartertime_export_erb-f1-miui_2019-10-17_6465fafb.awbucket.json'\n",
    "    ]:\n",
    "        new_events = aw_research.classify._get_events_smartertime(since, filepath=smartertime_awbucket_path)\n",
    "        events_smartertime = _union_no_overlap(events_smartertime, new_events)\n",
    "    for e in events_smartertime:\n",
    "        e.data['$source'] = 'smartertime'\n",
    "    return events_smartertime\n",
    "\n",
    "if 'smartertime' in datasources:\n",
    "        events_smartertime = load_smartertime()\n",
    "        verify_no_overlap(events_smartertime)\n",
    "        events = _union_no_overlap(events, events_smartertime)\n",
    "        verify_no_overlap(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Toggl data\n",
    "\n",
    "[Toggl](https://toggl.com/) is a web, desktop, and mobile app that lets you track time manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aw_research import load_toggl\n",
    "        \n",
    "if 'toggl' in datasources:\n",
    "    events_toggl = load_toggl(since, now)\n",
    "    print(f\"Oldest: {min(events_toggl, key=lambda e: e.timestamp).timestamp}\")\n",
    "    verify_no_overlap(events_toggl)\n",
    "    events = _union_no_overlap(events, events_toggl)\n",
    "    verify_no_overlap(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify data\n",
    "Just to make sure there are no bugs in underlying code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that no events are older than `since`\n",
    "assert all([since <= e.timestamp for e in events])\n",
    "\n",
    "# Verify that no events take place in the future\n",
    "# FIXME: Doesn't work with fake data, atm\n",
    "if 'fake' not in datasources:\n",
    "    assert all([e.timestamp + e.duration <= now for e in events])\n",
    "\n",
    "# Verify that no events overlap\n",
    "verify_no_overlap(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = Event(**{'data': {'title': 'event 1'},\n",
    "              'duration': timedelta(seconds=1, microseconds=599000),\n",
    "              'timestamp': datetime(2018, 12, 15, 16, 42, 0, 906000, tzinfo=timezone.utc)})\n",
    "e2 = Event(**{'data': {'title': 'event 2'},\n",
    "              'duration': timedelta(seconds=269, microseconds=602000),\n",
    "              'timestamp': datetime(2018, 12, 15, 16, 42, 0, 964000, tzinfo=timezone.utc)})\n",
    "\n",
    "es = _union_no_overlap([e1], [e2])\n",
    "verify_no_overlap(es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the distribution of event duration\n",
    "fig, ax = plt.subplots()\n",
    "xlim = 50\n",
    "pd.Series([e.duration.total_seconds() for e in events if e.duration.total_seconds() <= xlim]).plot.hist(bins=10, bottom=1)\n",
    "ax.set_xlabel('Seconds')\n",
    "ax.set_ylabel('# of events')\n",
    "ax.set_xlim(0, xlim)\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "#df = pd.DataFrame(pd.Series([e.duration.total_seconds() for e in events]))\n",
    "#df[\"dur\"] = (df[0] // 10) * 10\n",
    "#df[\"logdur\"] = log((df[0] * 1).round())\n",
    "#df[df[\"dur\"] > 10][\"dur\"].plot.hist()\n",
    "#df.groupby(\"dur\").mean() * df.groupby(\"dur\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_events = len(events)\n",
    "short_thres = 5\n",
    "short_events = len([e for e in events if e.duration.total_seconds() < short_thres])\n",
    "print(f\"# of total events:  {total_events}\")\n",
    "print(f\"# of events <{short_thres}s:    {short_events} ({round(100 * short_events/total_events)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Include sleep for improved coverage\n",
    "tracking_cov = __builtins__.sum((e.duration for e in events), timedelta()) / (now - since)\n",
    "print(f\"Tracking coverage: {100 * tracking_cov:.3}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate data\n",
    "\n",
    "Now we want to annotate our data with tags and categories.\n",
    "To do so we first need to specify tagging and classification rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define tagging rules\n",
    "\n",
    "First we need to specify rules used in categorization and tagging.\n",
    "\n",
    "To clarify:\n",
    "\n",
    " - An event can have **many** tags\n",
    " - An event can have **only one** category, but will also belong to that category's parent categories (creating a category hierarchy)\n",
    "\n",
    "The rules are specified by a list of tuples on the format `(regex, category, parent_category)`. You can write them within the notebook or load them from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    # (Social) Media\n",
    "    (r'Facebook|facebook.com', 'Social Media', 'Media'),\n",
    "    (r'Reddit|reddit.com', 'Social Media', 'Media'),\n",
    "    (r'Spotify|spotify.com', 'Music', 'Media'),\n",
    "    (r'subcategory without matching', 'Video', 'Media'),\n",
    "    (r'YouTube|youtube.com', 'YouTube', 'Video'),\n",
    "    (r'Plex|plex.tv', 'Plex', 'Video'),\n",
    "    (r'Fallout 4', 'Games', 'Media'),\n",
    "    \n",
    "    # Work\n",
    "    (r'github.com|stackoverflow.com', 'Programming', 'Work'),\n",
    "    (r'[Aa]ctivity[Ww]atch|aw-.*', 'ActivityWatch', 'Programming'),\n",
    "    (r'[Qq]uantified[Mm]e', 'QuantifiedMe', 'Programming'),\n",
    "    (r'[Tt]hankful', 'Thankful', 'Programming'),\n",
    "    \n",
    "    # School\n",
    "    (r'subcategory without matching', 'School', 'Work'),\n",
    "    (r'Duolingo|Brilliant|Khan Academy', 'Self-directed', 'School'),\n",
    "    (r'Analysis in One Variable', 'Maths', 'School'),\n",
    "    (r'Applied Machine Learning', 'CS', 'School'),\n",
    "    (r'Advanced Web Security', 'CS', 'School'),\n",
    "]\n",
    "\n",
    "# Now load the classes from within the notebook, or from a CSV file.\n",
    "load_from_file = True if personal else False\n",
    "if load_from_file:\n",
    "    aw_research.classify._init_classes(filename=\"./aw-research-sym/categories.toml\")\n",
    "else:\n",
    "    aw_research.classify._init_classes(new_classes=classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to actually annotate the events with our defined tags/categories we will use the `classify(events)` function which categorizes events by adding the fields `$tags` and `$category_hierarchy` to the event data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = aw_research.classify.classify(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize\n",
    "\n",
    "We know have events loaded from a variety of sources, annotated with categories and tags. **Here comes the fun part!**\n",
    "\n",
    "Here are some visualizations I've found useful to show how your activity today, over many days, and how much you've spent in each category.\n",
    "\n",
    "TODO: Add calendar heatmap plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today plot\n",
    "\n",
    "Barchart of which hours you've been active today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aw_research import split_event_on_hour, categorytime_per_day, categorytime_during_day, start_of_day, end_of_day\n",
    "    \n",
    "def plot_categorytime_during_day(events, category, color='teal'):\n",
    "    df = categorytime_during_day(events, category, today)\n",
    "    \n",
    "    # FIXME: This will make the first and last hour to always be 0\n",
    "    df[start_of_day(today) + day_offset - tz_offset] = 0 \n",
    "    df[end_of_day(today) + day_offset - tz_offset] = 0\n",
    "    df = df.sort_index().asfreq('H')\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 3))\n",
    "    ax = df.plot(kind='bar', color=color, rot=60)\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.title(category or \"All activity\")\n",
    "    \n",
    "    def label_format_hour(label):\n",
    "        \"\"\"\n",
    "        Convert time label to the format of pandas line plot\n",
    "        Based on: https://stackoverflow.com/a/53995225/965332\n",
    "        \"\"\"\n",
    "        label = label.replace(tzinfo=your_timezone)\n",
    "        label = label + label.utcoffset()\n",
    "        return f\"{label.hour}:{str(label.minute).ljust(2, '0')}\"  # if label.hour % 2 == 0 else ''\n",
    "        \n",
    "    ax.set_xticklabels(map(lambda x: label_format_hour(x), df.index))\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_categorytime_during_day(events, \"\")\n",
    "plot_categorytime_during_day(events, \"Work\", color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily time plot\n",
    "\n",
    "Useful to see how much you've engaged in a particular activity over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_category(cat, big=False):\n",
    "    fig = plt.figure(figsize=(18, 5 if big else 3))\n",
    "    #aw_research.classify._plot_category_daily_trend(events, [cat])\n",
    "    try:\n",
    "        ts  = categorytime_per_day(events, cat)\n",
    "    except Exception as e:\n",
    "        print(f\"Error for category '{cat}': {e}\")\n",
    "        return\n",
    "    ts.plot(label=f\": daily\", legend=True)\n",
    "    ts.rolling(7, min_periods=4).mean().plot(label=f\"7d SMA\", legend=True)\n",
    "    ts.rolling(30, min_periods=14).mean().plot(label=f\"30d SMA\", legend=True)\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(cat)\n",
    "    plt.xlim(pd.Timestamp(since), pd.Timestamp(now))\n",
    "    plt.ylim(0)\n",
    "    plt.grid(linestyle='--')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All logged activity\n",
    "plot_category('', big=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work-related\n",
    "plot_category('Work', big=True)\n",
    "plot_category('Programming')\n",
    "plot_category('ActivityWatch')\n",
    "plot_category('QuantifiedMe')\n",
    "plot_category('Thankful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# School-related\n",
    "plot_category('School')\n",
    "plot_category('Self-directed')\n",
    "plot_category('Maths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entertainment\n",
    "plot_category('Media', big=True)\n",
    "plot_category('Social Media')\n",
    "plot_category('Video')\n",
    "plot_category('Music')\n",
    "plot_category('Games')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category sunburst\n",
    "\n",
    "Uses the category hierarchy to create an overview of how time has been spent during a given period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_today = [e for e in events if today < e.timestamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sunburst(events):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    aw_research.classify._plot_category_hierarchy_sunburst(events)\n",
    "    display(HTML(f\"<h2>Duration: {__builtin__.sum((e.duration for e in events), timedelta(0))}</h2>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sunburst(events_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sunburst([e for e in events if today - timedelta(days=30) < e.timestamp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sunburst(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fictional wage plot\n",
    "\n",
    "Prioritizing things in life can be hard, and it's not uncommon to want to maximize how much you earn. But how much is working on project X actually worth to you in monetary terms? What about project Y?\n",
    "\n",
    "By assigning hourly wages to different categories we can plot which activities we've earned the most (fictional) money from! This can help you identify how much you expect to have earned both from different activities and in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_wages = {\n",
    "    #\"Work\": 200,\n",
    "    \"ActivityWatch\": 300,\n",
    "    \"QuantifiedMe\": 300,\n",
    "    \"Thankful\": 400,\n",
    "    \"School\": 600,\n",
    "    #\"Finance\": 1000,\n",
    "    #\"Maths\": 400,\n",
    "    #\"Control\": 400,\n",
    "}\n",
    "\n",
    "def plot_wages(events, category_wages):\n",
    "    df = pd.DataFrame()\n",
    "    for cat, wage in category_wages.items():\n",
    "        df[cat] = wage * categorytime_per_day(events, cat)\n",
    "    df.plot.area(label='total', stacked=True, legend=True, figsize=(16, 5))\n",
    "    df.sum(axis=1).rolling(7).mean().plot(label='Total 7d SMA', legend=True)\n",
    "    df.sum(axis=1).rolling(30).mean().plot(label='Total 30d SMA', legend=True)\n",
    "    plt.xlim(pd.Timestamp(since), pd.Timestamp(now))\n",
    "    plt.grid(linestyle='-.')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_wages(events, category_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncategorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def time_per_keyval(events, key):\n",
    "    vals = defaultdict(lambda: timedelta(0))\n",
    "    for e in events:\n",
    "        if key in e.data:\n",
    "            vals[e.data[key]] += e.duration\n",
    "        else:\n",
    "            vals[f'key {key} did not exist'] += e.duration\n",
    "    return vals\n",
    "\n",
    "def print_time_per_keyval(events, key):\n",
    "    from tabulate import tabulate\n",
    "    l = sorted([(v, k) for k, v in time_per_keyval(events, key).items()], reverse=True)\n",
    "    print(tabulate(l[:20], headers=['time', 'val']))\n",
    "    \n",
    "events_uncategorized = [e for e in events if 'Uncategorized' in e.data['$tags']]\n",
    "print_time_per_keyval(events_uncategorized, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_uncategorized_today = [e for e in events_uncategorized if e.timestamp > today]\n",
    "print_time_per_keyval(events_uncategorized_today, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_programming = [e for e in events if 'Work -> Programming' == e.data['$category_hierarchy']]\n",
    "print_time_per_keyval(events_programming, 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_time_per_keyval(events, '$source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's the end of the notebook!\n",
    "\n",
    "Thank you for checking it out! \n",
    "\n",
    "I hope you'll upvote and/or comment wherever you saw it to help it get seen!\n",
    "\n",
    " - TODO: Add \"cover image\" to give some sort of preview\n",
    "\n",
    "### Did you like it? Consider supporting us so we can keep building!\n",
    "\n",
    " - TODO: Add link/image/button to Patreon\n",
    " - Like ActivityWatch on AlternativeTo! (TODO: ...and ProductHunt)\n",
    " - Post about it on Twitter!\n",
    "\n",
    "### Run it yourself!\n",
    "\n",
    "You can run this notebook with your own data, it's a lot more fun! Check out the repo for details: https://github.com/ErikBjare/quantifiedme\n",
    "\n",
    " - TODO: Actually add details for how to run it in the README\n",
    " - TODO: Add prominent link/button to download ActivityWatch\n",
    " \n",
    "### Other interesting links\n",
    "\n",
    " - [Memento Labs](https://mementolabs.io/), a platform for self-study using quantified self data.\n",
    "\n",
    "### Thanks to\n",
    "\n",
    " - [Johan Bjäreholt](https://github.com/johan-bjareholt), for his amazing contributions, and for working on ActivityWatch with me for so long. **This wouldn't be possible without him.**\n",
    " - TODO: The reviewers\n",
    " - All the other contributors, whose [stats are listed here](http://activitywatch.net/contributors/).\n",
    " - Our Patrons/backers/supporters, your financial contribution means a lot!\n",
    " - [@karpathy](https://twitter.com/karpathy) for creating [ulogme](https://github.com/karpathy/ulogme), a spiritual ancestor of ActivityWatch\n",
    " - Our users, you motivate us to keep working!\n",
    " \n",
    " \n",
    " ## TODO: Post to\n",
    " \n",
    "  - Reddit\n",
    "  - Hacker News\n",
    "  - Twitter\n",
    "  - ActivityWatch Forum (under the 'Projects' category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
